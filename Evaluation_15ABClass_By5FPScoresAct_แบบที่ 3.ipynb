{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import efficientnet.tfkeras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Network 15AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir ='/media/tohn/SSD/ModelTrainByImages/R2_1/models/B5R2_block5_15AB_1FC_3.h5' #model\n",
    "model = load_model(model_dir)\n",
    "height = width = model.input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "import pandas as pd\n",
    "base_dir  = '/media/tohn/SSD/Images/Image/'#แก้\n",
    "dataframe = pd.read_csv( '/home/yupaporn/codes/USAI/Testdf.csv')#แก้\n",
    "validation_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "#Train\n",
    "train_df = pd.read_csv( '/home/yupaporn/codes/USAI/Traindf.csv')#แก้\n",
    "base_dir0 = '/media/tohn/SSD/Images/Image/'#แก้\n",
    "os.chdir(base_dir0)\n",
    "train_dir = os.path.join(base_dir0, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 22)\n",
      "(1312, 22)\n",
      "Normal:  (857, 22)\n",
      "Abnormal:  (455, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Case</th>\n",
       "      <th>Abs Position</th>\n",
       "      <th>Sub Position</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sub_class</th>\n",
       "      <th>Path Full</th>\n",
       "      <th>Path Crop</th>\n",
       "      <th>Views</th>\n",
       "      <th>...</th>\n",
       "      <th>originalImage</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Rleft</th>\n",
       "      <th>Rtop</th>\n",
       "      <th>Rwidth</th>\n",
       "      <th>Rheight</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>40</td>\n",
       "      <td>P1</td>\n",
       "      <td>P1</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>FP-A</td>\n",
       "      <td>...</td>\n",
       "      <td>https://irisprodseatraining.blob.core.windows....</td>\n",
       "      <td>86.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.092664</td>\n",
       "      <td>0.148873</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.346614</td>\n",
       "      <td>AB01 P1 C040.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>40</td>\n",
       "      <td>P2</td>\n",
       "      <td>P2</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>FP-A</td>\n",
       "      <td>...</td>\n",
       "      <td>https://irisprodseatraining.blob.core.windows....</td>\n",
       "      <td>163.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.171698</td>\n",
       "      <td>0.154849</td>\n",
       "      <td>0.560377</td>\n",
       "      <td>0.428287</td>\n",
       "      <td>AB01 P2 C040.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>40</td>\n",
       "      <td>P4</td>\n",
       "      <td>P41</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>...</td>\n",
       "      <td>https://irisprodseatraining.blob.core.windows....</td>\n",
       "      <td>127.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.140316</td>\n",
       "      <td>0.150865</td>\n",
       "      <td>0.667984</td>\n",
       "      <td>0.711155</td>\n",
       "      <td>AB01 P4-1 C040.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>40</td>\n",
       "      <td>P5</td>\n",
       "      <td>P51</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>...</td>\n",
       "      <td>https://irisprodseatraining.blob.core.windows....</td>\n",
       "      <td>59.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>0.063462</td>\n",
       "      <td>0.107041</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.653386</td>\n",
       "      <td>AB01 P5-1 C040.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>40</td>\n",
       "      <td>P3</td>\n",
       "      <td>P31</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>...</td>\n",
       "      <td>https://irisprodseatraining.blob.core.windows....</td>\n",
       "      <td>199.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>0.216374</td>\n",
       "      <td>0.146881</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.625498</td>\n",
       "      <td>AB01 P3-1 C040.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Case Abs Position Sub Position     Class  \\\n",
       "0         111           111    40           P1           P1  Abnormal   \n",
       "1         112           112    40           P2           P2  Abnormal   \n",
       "2         113           113    40           P4          P41  Abnormal   \n",
       "3         114           114    40           P5          P51  Abnormal   \n",
       "4         115           115    40           P3          P31  Abnormal   \n",
       "\n",
       "  Sub_class                                          Path Full  \\\n",
       "0      AB01  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "1      AB01  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "2      AB01  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "3      AB01  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "4      AB01  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "\n",
       "                                           Path Crop Views  ...  \\\n",
       "0  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  FP-A  ...   \n",
       "1  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  FP-A  ...   \n",
       "2  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  FP-B  ...   \n",
       "3  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  FP-C  ...   \n",
       "4  /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  FP-B  ...   \n",
       "\n",
       "                                       originalImage   left    top  width  \\\n",
       "0  https://irisprodseatraining.blob.core.windows....   86.0  133.0  477.0   \n",
       "1  https://irisprodseatraining.blob.core.windows....  163.0  139.0  532.0   \n",
       "2  https://irisprodseatraining.blob.core.windows....  127.0  135.0  605.0   \n",
       "3  https://irisprodseatraining.blob.core.windows....   59.0   96.0  643.0   \n",
       "4  https://irisprodseatraining.blob.core.windows....  199.0  132.0  618.0   \n",
       "\n",
       "   height     Rleft      Rtop    Rwidth   Rheight            filename  \n",
       "0   311.0  0.092664  0.148873  0.513514  0.346614    AB01 P1 C040.JPG  \n",
       "1   385.0  0.171698  0.154849  0.560377  0.428287    AB01 P2 C040.JPG  \n",
       "2   640.0  0.140316  0.150865  0.667984  0.711155  AB01 P4-1 C040.JPG  \n",
       "3   587.0  0.063462  0.107041  0.690385  0.653386  AB01 P5-1 C040.JPG  \n",
       "4   562.0  0.216374  0.146881  0.672515  0.625498  AB01 P3-1 C040.JPG  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df0 = pd.read_csv (r'/home/yupaporn/codes/USAI/Testdf.csv')\n",
    "print(df0 .shape)\n",
    "dataframe = df0[(df0['Path Crop']!='None' )&(df0['Path Crop']!='Nan')]\n",
    "print(dataframe.shape)\n",
    "print('Normal: ',dataframe[dataframe['Class']=='Normal'].shape)\n",
    "print('Abnormal: ',dataframe[dataframe['Class']=='Abnormal'].shape)\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1312 validated image filenames belonging to 15 classes.\n",
      "{0: 'AB01', 1: 'AB02', 2: 'AB03', 3: 'AB04', 4: 'AB05', 5: 'AB06', 6: 'AB07', 7: 'AB081', 8: 'AB082', 9: 'AB083', 10: 'AB09', 11: 'AB10', 12: 'AB11', 13: 'AB12', 14: 'Normal'}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      brightness_range=[0.5,1.5],\n",
    "      shear_range=0.4,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=False,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = train_dir,\n",
    "        x_col = 'Path Crop',\n",
    "        y_col = 'Sub_class',\n",
    "        target_size = (height, width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode= 'rgb',\n",
    "        class_mode='categorical')\n",
    "\n",
    "#label\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k.replace(\"C\",\"\")) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>15AB Class</th>\n",
       "      <th>AB01</th>\n",
       "      <th>AB02</th>\n",
       "      <th>AB03</th>\n",
       "      <th>AB04</th>\n",
       "      <th>AB05</th>\n",
       "      <th>AB06</th>\n",
       "      <th>AB07</th>\n",
       "      <th>AB081</th>\n",
       "      <th>AB082</th>\n",
       "      <th>AB083</th>\n",
       "      <th>AB09</th>\n",
       "      <th>AB10</th>\n",
       "      <th>AB11</th>\n",
       "      <th>AB12</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-FP Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP-A</th>\n",
       "      <td>84</td>\n",
       "      <td>109</td>\n",
       "      <td>42</td>\n",
       "      <td>84</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP-B</th>\n",
       "      <td>130</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP-C</th>\n",
       "      <td>81</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP-D</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>245</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP-E</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "15AB Class  AB01  AB02  AB03  AB04  AB05  AB06  AB07  AB081  AB082  AB083  \\\n",
       "5-FP Class                                                                  \n",
       "FP-A          84   109    42    84    34    59     2     22     21      8   \n",
       "FP-B         130   103    24    37    60     5    51     57     48     23   \n",
       "FP-C          81    61    19    38     4     0    21     45     40     12   \n",
       "FP-D           0     0     0    19     0     0     0      0      0      0   \n",
       "FP-E           0     0     0     0     0     0     0      0      0      0   \n",
       "\n",
       "15AB Class  AB09  AB10  AB11  AB12  Normal  \n",
       "5-FP Class                                  \n",
       "FP-A           0     0     0     0     596  \n",
       "FP-B           2     0     0     0    1063  \n",
       "FP-C          96    43    60     0    1015  \n",
       "FP-D           0     0    34   245     482  \n",
       "FP-E           0     0     0     0     278  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = pd.crosstab(train_df['Views'],train_df['Sub_class'],rownames=['5-FP Class'],colnames=['15AB Class'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_ = []\n",
    "for j in range(5) :\n",
    "    FP = list(conf_mat.iloc[j,:][0:14])\n",
    "    max_ = 11\n",
    "    fp = []\n",
    "    if j == 4:\n",
    "        fp = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1,1]\n",
    "        FP_.append(fp)\n",
    "    else:\n",
    "        for i in FP:\n",
    "    #         fp = []\n",
    "            if i >= max_:\n",
    "                a =1\n",
    "                fp.append(a)\n",
    "            elif i > 0 & i < max_ :\n",
    "                a =0.5\n",
    "                fp.append(a)                \n",
    "            else:\n",
    "                a =0\n",
    "                fp.append(a)\n",
    "        fp.append(1)\n",
    "        FP_.append(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0.5, 1, 1, 0.5, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 1, 0.5, 1, 1, 1, 1, 0.5, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 0.5, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP=np.array(FP_)\n",
    "FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['FPA','FPB','FPC','FPD','FPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB01</th>\n",
       "      <th>AB02</th>\n",
       "      <th>AB03</th>\n",
       "      <th>AB04</th>\n",
       "      <th>AB05</th>\n",
       "      <th>AB06</th>\n",
       "      <th>AB07</th>\n",
       "      <th>AB081</th>\n",
       "      <th>AB082</th>\n",
       "      <th>AB083</th>\n",
       "      <th>AB09</th>\n",
       "      <th>AB10</th>\n",
       "      <th>AB11</th>\n",
       "      <th>AB12</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AB01  AB02  AB03  AB04  AB05  AB06  AB07  AB081  AB082  AB083  AB09  AB10  \\\n",
       "0   1.0   1.0   1.0   1.0   1.0   1.0   0.5    1.0    1.0    0.5   0.0   0.0   \n",
       "1   1.0   1.0   1.0   1.0   1.0   0.5   1.0    1.0    1.0    1.0   0.5   0.0   \n",
       "2   1.0   1.0   1.0   1.0   0.5   0.0   1.0    1.0    1.0    1.0   1.0   1.0   \n",
       "3   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0   \n",
       "4   1.0   1.0   1.0   1.0   1.0   1.0   1.0    1.0    1.0    1.0   1.0   1.0   \n",
       "\n",
       "   AB11  AB12  Normal  \n",
       "0   0.0   0.0     1.0  \n",
       "1   0.0   0.0     1.0  \n",
       "2   1.0   0.0     1.0  \n",
       "3   1.0   1.0     1.0  \n",
       "4   1.0   1.0     1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.DataFrame(FP, columns = [ 'AB01','AB02','AB03', 'AB04', 'AB05', 'AB06', 'AB07', 'AB081', 'AB082', 'AB083', 'AB09', 'AB10', 'AB11', 'AB12', 'Normal'])\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  1.  1.  1.  1.  1.  0.5 1.  1.  0.5 0.  0.  0.  0.  1. ]\n",
      " [1.  1.  1.  1.  1.  0.5 1.  1.  1.  1.  0.5 0.  0.  0.  1. ]\n",
      " [1.  1.  1.  1.  0.5 0.  1.  1.  1.  1.  1.  1.  1.  0.  1. ]\n",
      " [0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "print(FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path):\n",
    "    # Read the image and resize it\n",
    "    img = image.load_img(img_path, target_size=(height, width))\n",
    "    # Convert it to a Numpy array with target shape.\n",
    "    x = image.img_to_array(img)\n",
    "    # Reshape\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    x /= 255.\n",
    "    result = model.predict([x])\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "pred_list = list()\n",
    "prob_list = list()\n",
    "pred_list_ = list()\n",
    "img_path=dataframe['Path Crop'].tolist()\n",
    "fp=dataframe['Views'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(img_path)):\n",
    "    print(i)\n",
    "    if fp[i] =='FP-A':\n",
    "        indx = 0\n",
    "    elif fp[i] =='FP-B':\n",
    "        indx = 1\n",
    "    elif fp[i] =='FP-C':\n",
    "        indx = 2\n",
    "    elif fp[i] =='FP-D':\n",
    "        indx = 3\n",
    "    else :\n",
    "        indx = 4\n",
    "    predict_ = predict_image(img_path[i])\n",
    "    prob = predict_*FP[indx]\n",
    "    result = np.argmax(prob)\n",
    "    pred_list_.append(labels[np.argmax(predict_)])\n",
    "    pred_list.append(labels[result])\n",
    "    prob_list.append(prob[result])\n",
    "    \n",
    "dataframe['category_old'] = pred_list_\n",
    "dataframe['category'] = pred_list\n",
    "dataframe['Prob'] = prob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15AB Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataframe\n",
    "#เช็คคลาสใน Predicted\n",
    "pred_class = set(data_train['category'])\n",
    "print('Predicted : ',len(pred_class))\n",
    "print(pred_class)\n",
    "#เช็คคลาสใน Actual\n",
    "classe = set(data_train['Sub_class'])\n",
    "print('Actual : ',len(classe))\n",
    "print(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "act = data_train['Sub_class'].array\n",
    "pred = data_train['category'].array\n",
    "\n",
    "cmat = confusion_matrix(act, pred)\n",
    "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
    "\n",
    "#Marking the Confusion Matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(act, pred))#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CF \n",
    "data = {'Actual': act,'Predicted' : pred,}\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(act, pred)\n",
    "\n",
    "#plot Confusion matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
    "ax.set_title('Confusion matrix',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=18)\n",
    "ax.set_xlabel('Predicted label',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abn&Nor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act= data_train['Sub_class'].map({'AB12':1, 'AB04':1, 'AB05':1, 'Normal':0, 'AB02':1, 'AB11':1, 'AB082':1, 'AB06':1,'AB07':1, 'AB081':1, 'AB09':1, 'AB03':1, 'AB10':1, 'AB01':1, 'AB083':1}).values\n",
    "pred = data_train['category'].map({'AB12':1, 'AB04':1, 'AB05':1, 'Normal':0, 'AB02':1, 'AB11':1, 'AB082':1, 'AB06':1,'AB07':1, 'AB081':1, 'AB09':1, 'AB03':1, 'AB10':1, 'AB01':1, 'AB083':1}).values\n",
    "cmat = confusion_matrix(act, pred)\n",
    "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
    "\n",
    "#Marking the Confusion Matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(act, pred))#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CF \n",
    "data = {'Actual': act,'Predicted' : pred,}\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(act, pred)\n",
    "TN, FP, FN, TP = confusion_matrix(act, pred).ravel()\n",
    "print(TN, FP, FN, TP)\n",
    "#plot Confusion matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
    "ax.set_title('Confusion matrix',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=18)\n",
    "ax.set_xlabel('Predicted label',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = pd.crosstab(df0['Views'],df0['Sub_class'],rownames=['5-FP Class'],colnames=['15AB Class'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_ = []\n",
    "for j in range(5) :\n",
    "    FP = list(conf_mat.iloc[j,:][0:14])\n",
    "    max_ = 11\n",
    "    fp = []\n",
    "    if j == 4:\n",
    "        fp = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1,1]\n",
    "        FP_.append(fp)\n",
    "    else:\n",
    "        for i in FP:\n",
    "    #         fp = []\n",
    "            if i >= max_:\n",
    "                a =1\n",
    "                fp.append(a)\n",
    "            elif i > 0 & i < max_ :\n",
    "                a =0.5\n",
    "                fp.append(a)                \n",
    "            else:\n",
    "                a =0\n",
    "                fp.append(a)\n",
    "        fp.append(1)\n",
    "        FP_.append(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP=np.array(FP_)\n",
    "FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: 'AB01', 1: 'AB02', 2: 'AB03', 3: 'AB04', 4: 'AB05', 5: 'AB06', 6: 'AB07', 7: 'AB081', 8: 'AB082', 9: 'AB083', 10: 'AB09', 11: 'AB10', 12: 'AB11', 13: 'AB12', 14: 'Normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path):\n",
    "    # Read the image and resize it\n",
    "    img = image.load_img(img_path, target_size=(height, width))\n",
    "    # Convert it to a Numpy array with target shape.\n",
    "    x = image.img_to_array(img)\n",
    "    # Reshape\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    x /= 255.\n",
    "    result = model.predict([x])\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "pred_list = list()\n",
    "prob_list = list()\n",
    "pred_list_ = list()\n",
    "img_path=dataframe['Path Crop'].tolist()\n",
    "fp=dataframe['Views'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_list = list()\n",
    "prob_list = list()\n",
    "\n",
    "for i in range(0,len(img_path)):\n",
    "    print(i)\n",
    "    print(fp[i])\n",
    "    if fp[i] =='FP-A':\n",
    "        indx = 0\n",
    "    elif fp[i] =='FP-B':\n",
    "        indx = 1\n",
    "    elif fp[i] =='FP-C':\n",
    "        indx = 2\n",
    "    elif fp[i] =='FP-D':\n",
    "        indx = 3\n",
    "    else :\n",
    "        indx = 4\n",
    "    predict_ = predict_image(img_path[i])\n",
    "    result = predict_*FP[indx]\n",
    "    re_class = list()\n",
    "    re_prop = list()\n",
    "    while len(re_class) <3:\n",
    "#         print(i)\n",
    "        maxx = np.argmax(result)\n",
    "        re_class.append(labels[maxx])\n",
    "        re_prop.append(result[maxx])\n",
    "        result = np.where(result==result[maxx], 0, result)\n",
    "    pred_list.append(re_class)\n",
    "    prob_list.append(re_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['category_top3'] = pred_list\n",
    "dataframe['Prob_top3'] = prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress = list()\n",
    "ress_class = list()\n",
    "for i in range(0,len(dataframe)):\n",
    "    if dataframe['Sub_class'][i] in dataframe['category_top3'][i]:\n",
    "        res = dataframe['Sub_class'][i]\n",
    "    else:\n",
    "        res = dataframe['category'][i]\n",
    "    ress.append(res)\n",
    "dataframe['Pred_top3'] = ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Act_ = data_train['Sub_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = confusion_matrix(Act_, ress)\n",
    "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
    "\n",
    "#Marking the Confusion Matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(Act_, ress))#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CF \n",
    "data = {'Actual': Act_,'Predicted' : ress,}\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(Act_, ress)\n",
    "\n",
    "#plot Confusion matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
    "ax.set_title('Confusion matrix',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=18)\n",
    "ax.set_xlabel('Predicted label',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act= dataframe['Sub_class'].map({'AB12':1, 'AB04':1, 'AB05':1, 'Normal':0, 'AB02':1, 'AB11':1, 'AB082':1, 'AB06':1,'AB07':1, 'AB081':1, 'AB09':1, 'AB03':1, 'AB10':1, 'AB01':1, 'AB083':1}).values\n",
    "pred= dataframe['Pred_top3'].map({'AB12':1, 'AB04':1, 'AB05':1, 'Normal':0, 'AB02':1, 'AB11':1, 'AB082':1, 'AB06':1,'AB07':1, 'AB081':1, 'AB09':1, 'AB03':1, 'AB10':1, 'AB01':1, 'AB083':1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = confusion_matrix(act, pred)\n",
    "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
    "\n",
    "#Marking the Confusion Matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(act, pred))#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CF \n",
    "data = {'Actual': act,'Predicted' : pred,}\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(act, pred)\n",
    "TN, FP, FN, TP = confusion_matrix(act, pred).ravel()\n",
    "print(TN, FP, FN, TP)\n",
    "#plot Confusion matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
    "ax.set_title('Confusion matrix',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3\n",
    "# Test_df = pd.read_csv( '/home/yupaporn/CSV_file/result_BiTNet_FPScores.csv')#แก้\n",
    "# Test_df['15AB_FPAct_3'] = dataframe['category']\n",
    "# Test_df['Prob_FPAct_3'] = dataframe['Prob']\n",
    "# Test_df.to_csv('/home/yupaporn/CSV_file/result_BiTNet_FPScores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USAI3",
   "language": "python",
   "name": "usai3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
